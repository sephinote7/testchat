import {
  useState,
  useRef,
  useCallback,
  useImperativeHandle,
  forwardRef,
  useEffect,
} from 'react';
import './RecordPanel.css';

/**
 * [ìµœì¢… ìˆ˜ì •ë³¸]
 * - ê³ í™”ì§ˆ: ë¡œì»¬ ì €ì¥ìš© (Canvas í•©ì„± ì˜ìƒ + í•©ì„± ìŒì„±)
 * - ì €ìš©ëŸ‰: AI ìš”ì•½ìš© (í•©ì„± ìŒì„± ì „ìš©)
 */
const RecordPanel = forwardRef(function RecordPanel(
  {
    localStream,
    remoteStream,
    disabled,
    autoStart = false,
    showDownload = true,
  },
  ref,
) {
  const [isRecording, setIsRecording] = useState(false);
  const [lastBlob, setLastBlob] = useState(null);
  const [lastAudioBlob, setLastAudioBlob] = useState(null);

  // ë ˆì½”ë” ë° ë°ì´í„° ì°¸ì¡°
  const mediaRecorderRef = useRef(null);
  const audioRecorderRef = useRef(null);
  const localAudioRecorderRef = useRef(null);
  const remoteAudioRecorderRef = useRef(null);
  const chunksRef = useRef([]);
  const audioChunksRef = useRef([]);
  const localAudioChunksRef = useRef([]);
  const remoteAudioChunksRef = useRef([]);
  const requestRef = useRef(null);
  const audioContextRef = useRef(null);
  const blobForApiRef = useRef(null);
  const localAudioBlobRef = useRef(null);
  const remoteAudioBlobRef = useRef(null);

  const canRecord = Boolean(localStream && remoteStream && !disabled);

  // ë…¹í™” ì¤‘ì§€ í•¨ìˆ˜ (startRecordingë³´ë‹¤ ë¨¼ì € ì •ì˜í•´ ìƒí˜¸ ì°¸ì¡° íšŒí”¼)
  const stopRecording = useCallback(() => {
    console.log('ë…¹í™” ì¤‘ì§€ ì‹œë„...');
    setIsRecording(false);

    // 1. ëª¨ë“  ë ˆì½”ë” ì •ì§€
    [
      mediaRecorderRef,
      audioRecorderRef,
      localAudioRecorderRef,
      remoteAudioRecorderRef,
    ].forEach((ref) => {
      if (ref.current && ref.current.state !== 'inactive') {
        ref.current.stop();
      }
    });

    // 2. ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ ì¤‘ë‹¨
    if (requestRef.current) {
      cancelAnimationFrame(requestRef.current);
    }

    // 3. [ì¶”ê°€] ì‹¤ì œ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ ì¤‘ì§€ (ë²„í¼ ë¹„ìš°ê¸° ê°•ì œ)
    if (localStream) localStream.getTracks().forEach((track) => track.stop());
    if (remoteStream) remoteStream.getTracks().forEach((track) => track.stop());
  }, [localStream, remoteStream]);

  // í†µí™”ê°€ ëŠê¸°ë©´ ìë™ìœ¼ë¡œ ë…¹í™” ì¤‘ì§€
  useEffect(() => {
    if ((!autoStart || !canRecord) && isRecording) {
      stopRecording();
    }
  }, [autoStart, canRecord, isRecording, stopRecording]);

  // ë…¹í™” ì‹œì‘ í•¨ìˆ˜
  const startRecording = useCallback(async () => {
    if (!localStream || !remoteStream || isRecording) return;

    try {
      console.log('ë…¹í™” í”„ë¡œì„¸ìŠ¤ ì‹œì‘...');
      chunksRef.current = [];
      audioChunksRef.current = [];
      localAudioChunksRef.current = [];
      remoteAudioChunksRef.current = [];
      blobForApiRef.current = null;
      localAudioBlobRef.current = null;
      remoteAudioBlobRef.current = null;

      // 1. AudioContext ìƒì„±
      const audioContext = new (
        window.AudioContext || window.webkitAudioContext
      )();
      if (audioContext.state === 'suspended') await audioContext.resume();
      audioContextRef.current = audioContext;

      // 2. ì¤‘ê°„ ë‹¤ë¦¬(GainNode)ì™€ ëª©ì ì§€(Destination) ìƒì„±
      // GainNodeëŠ” ì…ë ¥ì´ ì—†ì–´ë„ ì¶œë ¥ì„ í˜•ì„±í•˜ë¯€ë¡œ IndexSizeErrorë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
      const mixer = audioContext.createGain();
      const dest = audioContext.createMediaStreamDestination();
      mixer.connect(dest);

      // 3. ë¶„ì„ê¸°(Analyzer)ë¥¼ mixerì— ì—°ê²° (ì´ì œ ë§¤ìš° ì•ˆì „í•¨)
      const analyzer = audioContext.createAnalyser();
      mixer.connect(analyzer);

      // 4. ì‹¤ì œ ì˜¤ë””ì˜¤ ì†ŒìŠ¤ë“¤ì„ mixerì— ì—°ê²°
      let hasAudio = false;
      [localStream, remoteStream].forEach((stream, index) => {
        const tracks = stream.getAudioTracks();
        if (tracks.length > 0 && tracks[0].readyState === 'live') {
          try {
            const source = audioContext.createMediaStreamSource(
              new MediaStream([tracks[0]]),
            );
            source.connect(mixer); // dest ëŒ€ì‹  mixerì— ì—°ê²°
            hasAudio = true;
            console.log(`${index === 0 ? 'ë‚´' : 'ìƒëŒ€'} ë§ˆì´í¬ ë…¸ë“œ ì—°ê²° ì„±ê³µ`);
          } catch (e) {
            console.warn(
              `${index === 0 ? 'ë‚´' : 'ìƒëŒ€'} ì˜¤ë””ì˜¤ ë…¸ë“œ ìƒì„± ì‹¤íŒ¨:`,
              e,
            );
          }
        }
      });

      // 5. ë³¼ë¥¨ ì²´í¬ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
      const dataArray = new Uint8Array(analyzer.frequencyBinCount);
      const checkVolume = () => {
        if (!audioContext || audioContext.state === 'closed') return;
        analyzer.getByteFrequencyData(dataArray);
        const volume = dataArray.reduce((a, b) => a + b) / dataArray.length;
        if (volume > 0 && Math.random() > 0.98) {
          console.log('ğŸ¤ ì˜¤ë””ì˜¤ ì‹ í˜¸ ë ˆë²¨:', volume.toFixed(2));
        }
        requestRef.current = requestAnimationFrame(checkVolume);
      };
      checkVolume();

      // 6. ë¹„ë””ì˜¤ í•©ì„± ë° Canvas ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
      // 4. ë¹„ë””ì˜¤ í•©ì„± ì„¤ì • ë³´ì™„
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = 1280;
      canvas.height = 480;

      const localVideo = document.createElement('video');
      const remoteVideo = document.createElement('video');

      // [ì¤‘ìš”] ë¸Œë¼ìš°ì € ì •ì±… ëŒ€ì‘ ì†ì„± ì¶”ê°€
      [localVideo, remoteVideo].forEach((v) => {
        v.muted = true;
        v.autoplay = true;
        v.playsInline = true; // ëª¨ë°”ì¼ ë° ì¼ë¶€ í™˜ê²½ í•„ìˆ˜
      });

      localVideo.srcObject = localStream;
      remoteVideo.srcObject = remoteStream;

      // ë¹„ë””ì˜¤ê°€ ì‹¤ì œë¡œ ì¬ìƒë  ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ëŠ” ë¡œì§ ê°•í™”
      const playVideo = (video) => {
        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            video
              .play()
              .then(resolve)
              .catch((e) => console.error('ì¬ìƒ ì‹¤íŒ¨:', e));
          };
        });
      };

      await Promise.all([playVideo(localVideo), playVideo(remoteVideo)]);

      console.log('ë¹„ë””ì˜¤ ì¬ìƒ ì‹œì‘ë¨, ìº”ë²„ìŠ¤ ë“œë¡œì‰ ê°œì‹œ');

      const draw = () => {
        if (!isRecording && mediaRecorderRef.current?.state === 'inactive')
          return;

        ctx.fillStyle = 'black';
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        // ì˜ìƒì´ ì‹¤ì œë¡œ ì¶œë ¥ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ ì²´í¬ í›„ ê·¸ë¦¬ê¸°
        if (localVideo.readyState >= 2) {
          ctx.drawImage(localVideo, 0, 0, 640, 480);
        }
        if (remoteVideo.readyState >= 2) {
          ctx.drawImage(remoteVideo, 640, 0, 640, 480);
        }

        requestRef.current = requestAnimationFrame(draw);
      };
      draw();

      // 7. ìµœì¢… ë ˆì½”ë” ì„¤ì •
      const canvasStream = canvas.captureStream(30);
      // ë¹„ë””ì˜¤ íŠ¸ë™ + ë¯¹ì„œì—ì„œ ë‚˜ì˜¨ ì˜¤ë””ì˜¤ íŠ¸ë™ í•©ì¹˜ê¸°
      const finalStream = new MediaStream([
        ...canvasStream.getVideoTracks(),
        ...dest.stream.getAudioTracks(),
      ]);

      const recorder = new MediaRecorder(finalStream, {
        mimeType: 'video/webm',
      });
      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunksRef.current.push(e.data);
      };
      recorder.onstop = () => {
        if (chunksRef.current.length > 0) {
          const blob = new Blob(chunksRef.current, { type: 'video/webm' });
          setLastBlob(blob);
          if (!blobForApiRef.current) blobForApiRef.current = blob;
        }
      };

      if (hasAudio) {
        const audioRecorder = new MediaRecorder(dest.stream, {
          mimeType: 'audio/webm',
        });
        audioRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) audioChunksRef.current.push(e.data);
        };
        audioRecorder.onstop = () => {
          if (audioChunksRef.current.length > 0) {
            const blob = new Blob(audioChunksRef.current, {
              type: 'audio/webm',
            });
            setLastAudioBlob(blob);
            blobForApiRef.current = blob;
          }
        };
        audioRecorder.start(1000);
        audioRecorderRef.current = audioRecorder;
      }

      // ë¡œì»¬/ì›ê²© ì˜¤ë””ì˜¤ë¥¼ ë³„ë„ ë…¹ìŒ (STT speaker ë¶„ë¦¬ìš©)
      const localTrack = localStream.getAudioTracks?.()[0];
      if (localTrack && localTrack.readyState === 'live') {
        const localOnlyStream = new MediaStream([localTrack]);
        const lr = new MediaRecorder(localOnlyStream, {
          mimeType: 'audio/webm',
        });
        lr.ondataavailable = (e) => {
          if (e.data.size > 0) localAudioChunksRef.current.push(e.data);
        };
        lr.onstop = () => {
          if (localAudioChunksRef.current.length > 0) {
            localAudioBlobRef.current = new Blob(localAudioChunksRef.current, {
              type: 'audio/webm',
            });
          } else {
            localAudioBlobRef.current = null;
          }
        };
        lr.start(1000);
        localAudioRecorderRef.current = lr;
      }

      const remoteTrack = remoteStream.getAudioTracks?.()[0];
      if (remoteTrack && remoteTrack.readyState === 'live') {
        const remoteOnlyStream = new MediaStream([remoteTrack]);
        const rr = new MediaRecorder(remoteOnlyStream, {
          mimeType: 'audio/webm',
        });
        rr.ondataavailable = (e) => {
          if (e.data.size > 0) remoteAudioChunksRef.current.push(e.data);
        };
        rr.onstop = () => {
          if (remoteAudioChunksRef.current.length > 0) {
            remoteAudioBlobRef.current = new Blob(
              remoteAudioChunksRef.current,
              {
                type: 'audio/webm',
              },
            );
          } else {
            remoteAudioBlobRef.current = null;
          }
        };
        rr.start(1000);
        remoteAudioRecorderRef.current = rr;
      }

      recorder.start(1000);
      mediaRecorderRef.current = recorder;
      setIsRecording(true);
    } catch (err) {
      console.error('ë…¹í™” ì‹œì‘ ì¹˜ëª…ì  ì˜¤ë¥˜:', err);
    }
  }, [localStream, remoteStream, isRecording]);

  // ë§¤ì¹­(í†µí™” ì—°ê²°) ì‹œ ìë™ ë…¹í™” ì‹œì‘ â€” startRecording ì •ì˜ ì´í›„ì— ë°°ì¹˜í•´ TDZ ë°©ì§€
  useEffect(() => {
    if (autoStart && canRecord && !isRecording && startRecording) {
      startRecording();
    }
  }, [autoStart, canRecord, isRecording, startRecording]);

  // ë‚˜ë¨¸ì§€ ê¸°ëŠ¥ë“¤ (ë‹¤ìš´ë¡œë“œ, ìš”ì•½ ì „ì†¡ ë“±)
  const downloadRecording = useCallback(() => {
    if (!lastBlob) return;
    const url = URL.createObjectURL(lastBlob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `ìƒë‹´ë…¹í™”_${new Date().toLocaleString()}.webm`;
    a.click();
    URL.revokeObjectURL(url);
  }, [lastBlob]);

  // ì™¸ë¶€(App.js)ì—ì„œ ì œì–´í•˜ê¸° ìœ„í•œ ref ë…¸ì¶œ
  useImperativeHandle(ref, () => ({
    stopRecordingAndGetBlob: async () => {
      stopRecording();
      return new Promise((resolve) => {
        const deadline = Date.now() + 2000;
        const tick = () => {
          if (blobForApiRef.current) {
            resolve(blobForApiRef.current);
            return;
          }
          if (Date.now() < deadline) setTimeout(tick, 150);
          else resolve(null);
        };
        setTimeout(tick, 200);
      });
    },
    stopRecordingAndGetBlobs: async () => {
      stopRecording();
      return new Promise((resolve) => {
        const deadline = Date.now() + 2500;
        const tick = () => {
          const any =
            blobForApiRef.current ||
            localAudioBlobRef.current ||
            remoteAudioBlobRef.current ||
            lastBlob;
          if (any) {
            resolve({
              mixedAudioBlob: blobForApiRef.current || null,
              localAudioBlob: localAudioBlobRef.current || null,
              remoteAudioBlob: remoteAudioBlobRef.current || null,
              videoBlob: lastBlob || null,
            });
            return;
          }
          if (Date.now() < deadline) setTimeout(tick, 150);
          else
            resolve({
              mixedAudioBlob: blobForApiRef.current || null,
              localAudioBlob: localAudioBlobRef.current || null,
              remoteAudioBlob: remoteAudioBlobRef.current || null,
              videoBlob: lastBlob || null,
            });
        };
        setTimeout(tick, 200);
      });
    },
  }));

  return (
    <section className="record-panel">
      <h3>í™”ë©´ í•©ì„± ë…¹í™”</h3>
      <p className="record-hint">
        í†µí™” ì—°ê²° ì‹œ ìë™ìœ¼ë¡œ ë…¹í™”ë˜ë©°, í†µí™” ì¢…ë£Œ ì‹œ ë‹¤ìš´ë¡œë“œê°€ í™œì„±í™”ë©ë‹ˆë‹¤.
      </p>

      {isRecording && <div className="recording-indicator">ğŸ”´ ë…¹í™” ì¤‘...</div>}

      {(lastBlob || lastAudioBlob) && (
        <div className="record-result fade-in">
          <div className="record-info">
            <span>âœ… ë…¹í™” ì™„ë£Œ: </span>
            {lastBlob && (
              <small>
                ê³ í™”ì§ˆ ì˜ìƒ ({(lastBlob.size / 1024 / 1024).toFixed(1)}MB)
              </small>
            )}
            {lastAudioBlob && (
              <small>
                {' '}
                / ìš”ì•½ìš© ìŒì„± ({(lastAudioBlob.size / 1024).toFixed(1)}KB)
              </small>
            )}
          </div>

          <div className="record-result-actions">
            {showDownload && (
              <button
                type="button"
                onClick={downloadRecording}
                className="btn-download"
              >
                PCì— ê³ í™”ì§ˆ ì €ì¥
              </button>
            )}
          </div>
        </div>
      )}
    </section>
  );
});

export default RecordPanel;
